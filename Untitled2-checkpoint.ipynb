{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 95.85%\n",
      "Testing accuracy: 90.80%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "# download and read mnist\n",
    "mnist = fetch_mldata('MNIST original', data_home='./')\n",
    "\n",
    "# 'mnist.data' is 70k x 784 array, each row represents the pixels from a 28x28=784 image\n",
    "# 'mnist.target' is 70k x 1 array, each row represents the target class of the corresponding image\n",
    "images = mnist.data\n",
    "targets = mnist.target\n",
    "\n",
    "# make the value of pixels from [0, 255] to [0, 1] for further process\n",
    "X = mnist.data / 255.\n",
    "Y = mnist.target\n",
    "\n",
    "# print the first image of the dataset\n",
    "#img1 = X[0].reshape(28, 28)\n",
    "#plt.imshow(img1, cmap='gray')\n",
    "#plt.show()\n",
    "\n",
    "# print the images after simple transformation\n",
    "#img2 = 1 - img1\n",
    "#plt.imshow(img2, cmap='gray')\n",
    "#plt.show()\n",
    "\n",
    "#img3 = img1.transpose()\n",
    "#plt.imshow(img3, cmap='gray')\n",
    "#plt.show()\n",
    "\n",
    "# split data to train and test (for faster calculation, just use 1/10 data)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X[::10], Y[::10], test_size=1000)\n",
    "\n",
    "# TODO:use logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train ,Y_train) #train the logic regression model\n",
    "\n",
    "y_test = logreg.predict(X_test) #get prediction of the test set\n",
    "\n",
    "test_accuracy = metrics.accuracy_score(Y_test , y_test)\n",
    "\n",
    "y_train = logreg.predict(X_train) #get prediction of the train set\n",
    "\n",
    "train_accuracy = metrics.accuracy_score(Y_train , y_train)\n",
    "\n",
    "print('Training accuracy: %0.2f%%' % (train_accuracy*100))\n",
    "print('Testing accuracy: %0.2f%%' % (test_accuracy*100))\n",
    "\n",
    "\n",
    "#Training accuracy: 95.85%\n",
    "#Testing accuracy: 90.80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 84.20%\n",
      "Testing accuracy: 82.40%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "# download and read mnist\n",
    "mnist = fetch_mldata('MNIST original', data_home='./')\n",
    "\n",
    "# 'mnist.data' is 70k x 784 array, each row represents the pixels from a 28x28=784 image\n",
    "# 'mnist.target' is 70k x 1 array, each row represents the target class of the corresponding image\n",
    "images = mnist.data\n",
    "targets = mnist.target\n",
    "\n",
    "# make the value of pixels from [0, 255] to [0, 1] for further process\n",
    "X = mnist.data / 255.\n",
    "Y = mnist.target\n",
    "\n",
    "# split data to train and test (for faster calculation, just use 1/10 data)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X[::10], Y[::10], test_size=1000)\n",
    "\n",
    "# TODO:use naive bayes\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics\n",
    "\n",
    "nb=BernoulliNB()\n",
    "nb.fit(X_train ,Y_train)\n",
    "\n",
    "y_train=nb.predict(X_train)\n",
    "y_test=nb.predict(X_test)\n",
    "\n",
    "train_accuracy=metrics.accuracy_score(Y_train , y_train)\n",
    "test_accuracy=metrics.accuracy_score(Y_test , y_test)\n",
    "print('Training accuracy: %0.2f%%' % (train_accuracy*100))\n",
    "print('Testing accuracy: %0.2f%%' % (test_accuracy*100))\n",
    "\n",
    "\n",
    "#Training accuracy: 84.20%\n",
    "#Testing accuracy: 82.40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 98.23%\n",
      "Testing accuracy: 87.60%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "# download and read mnist\n",
    "mnist = fetch_mldata('MNIST original', data_home='./')\n",
    "\n",
    "# 'mnist.data' is 70k x 784 array, each row represents the pixels from a 28x28=784 image\n",
    "# 'mnist.target' is 70k x 1 array, each row represents the target class of the corresponding image\n",
    "images = mnist.data\n",
    "targets = mnist.target\n",
    "\n",
    "# make the value of pixels from [0, 255] to [0, 1] for further process\n",
    "X = mnist.data / 255.\n",
    "Y = mnist.target\n",
    "\n",
    "# split data to train and test (for faster calculation, just use 1/10 data)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X[::10], Y[::10], test_size=1000)\n",
    "\n",
    "# TODO:use support vector machine\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "\n",
    "svm=LinearSVC()\n",
    "svm.fit(X_train ,Y_train)\n",
    "\n",
    "y_train=svm.predict(X_train)\n",
    "y_test=svm.predict(X_test)\n",
    "\n",
    "train_accuracy=metrics.accuracy_score(Y_train , y_train)\n",
    "test_accuracy=metrics.accuracy_score(Y_test , y_test)\n",
    "print('Training accuracy: %0.2f%%' % (train_accuracy*100))\n",
    "print('Testing accuracy: %0.2f%%' % (test_accuracy*100))\n",
    "\n",
    "\n",
    "#Training accuracy: 98.18%\n",
    "#Testing accuracy: 86.50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "# download and read mnist\n",
    "mnist = fetch_mldata('MNIST original', data_home='./')\n",
    "\n",
    "# 'mnist.data' is 70k x 784 array, each row represents the pixels from a 28x28=784 image\n",
    "# 'mnist.target' is 70k x 1 array, each row represents the target class of the corresponding image\n",
    "images = mnist.data\n",
    "targets = mnist.target\n",
    "\n",
    "# make the value of pixels from [0, 255] to [0, 1] for further process\n",
    "X = mnist.data / 255.\n",
    "Y = mnist.target\n",
    "\n",
    "# split data to train and test (for faster calculation, just use 1/10 data)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X[::10], Y[::10], test_size=1000)\n",
    "\n",
    "# TODO:use SVM with another group of parameters\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "svm=SVC(kernel='linear')\n",
    "svm.fit(X_train ,Y_train)\n",
    "\n",
    "y_train=svm.predict(X_train)\n",
    "y_test=svm.predict(X_test)\n",
    "\n",
    "train_accuracy=metrics.accuracy_score(Y_train , y_train)\n",
    "test_accuracy=metrics.accuracy_score(Y_test , y_test)\n",
    "print('Training accuracy: %0.2f%%' % (train_accuracy*100))\n",
    "print('Testing accuracy: %0.2f%%' % (test_accuracy*100))\n",
    "\n",
    "#linear kernel\n",
    "#Training accuracy: 99.97%\n",
    "#Testing accuracy: 91.00%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-0d5e034b9e7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# preprocessing\n",
    "normalize = transforms.Normalize(mean=[.5], std=[.5])\n",
    "transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "# download and load the data\n",
    "train_dataset = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./mnist/', train=False, transform=transform, download=False)\n",
    "\n",
    "# encapsulate them into dataloader form\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "\n",
    "test_x = Variable(torch.unsqueeze(test_data.test_data, dim=1), volatile=True).type(torch.FloatTensor)[:2000]/255.   # shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)\n",
    "test_y = test_data.test_labels[:2000]\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5,stride=1,padding=2,),nn.ReLU(),nn.MaxPool2d(kernel_size=2),)\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(16, 32, 5, 1, 2),nn.ReLU(),nn.MaxPool2d(2),)\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "    def forward(self, x):        \n",
    "        x = self.conv1(x)        \n",
    "        x = self.conv2(x)        \n",
    "        x = x.view(x.size(0), -1)                 \n",
    "        output = self.out(x)        \n",
    "        return output, x \n",
    "# TODO:define model \n",
    "\n",
    "model = SimpleNet()\n",
    "\n",
    "# TODO:define loss function and optimiter\n",
    "criterion =nn.CrossEntropyLoss() \n",
    "optimizer =optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# train and evaluate\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        # TODO:forward + backward + optimize\n",
    "        tr_x = Variable(images)\n",
    "        tr_y = Variable(labels)\n",
    "        output = model(tr_x)[0]\n",
    "        loss = criterion(output, tr_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        if step%128==0:\n",
    "            output = model(test_x)\n",
    "            y_test = torch.max(output, 1)[1].data.squeeze()\n",
    "            test_accuracy = sum(y_test == test_y) / float(test_y.size(0))\n",
    "        \n",
    "    # evaluate\n",
    "    # TODO:calculate the accuracy using traning and testing dataset\n",
    "print('Testing accuracy: %0.2f%%' % (test_accuracy*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
